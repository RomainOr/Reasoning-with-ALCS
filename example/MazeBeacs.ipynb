{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    file, You can obtain one at http://mozilla.org/MPL/2.0/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Enable automatic module reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# To ease the loading of modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load BEACS module\n",
    "from beacs.agents.beacs import BEACS, Configuration\n",
    "\n",
    "# Load Metrics\n",
    "from example.metrics.MazeMetrics import \\\n",
    "    _maze_metrics, \\\n",
    "    _how_many_peps_match_non_aliased_states, \\\n",
    "    _mean_reliable_classifier_specificity, \\\n",
    "    _when_full_knowledge_is_achieved, \\\n",
    "    _enhanced_effect_error\n",
    "\n",
    "# Load Plotting Wrappers\n",
    "from example.metrics.MazePlottingWrapper import \\\n",
    "    parse_metrics_to_df, \\\n",
    "    plot_performance\n",
    "\n",
    "# Load environments\n",
    "import gym\n",
    "import my_mazes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent - BEACS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Environmental Set Up\n",
    "RANDOM_ATTRIBUTE_LENGTH = 0\n",
    "CLASSIFIER_LENGTH = 8 + RANDOM_ATTRIBUTE_LENGTH\n",
    "NUMBER_OF_POSSIBLE_ACTIONS = 8\n",
    "SLIPPERY_PROB = 0.\n",
    "MAZE = \"Woods101-v0\"\n",
    "\n",
    "#Exploration Set Up\n",
    "NUMBER_OF_EXPLORE_TRIALS = 5000\n",
    "METRICS_TRIAL_FREQUENCY_EXPLORE = 100\n",
    "EPSILON = 0.8\n",
    "\n",
    "#Exploitation Set Up\n",
    "NUMBER_OF_EXPLOIT_TRIALS_NO_RL = 500\n",
    "BETA_EXPLOIT_NO_RL = 0.00\n",
    "NUMBER_OF_EXPLOIT_TRIALS_RL_START = 500\n",
    "BETA_EXPLOIT_RL_START = 0.05\n",
    "NUMBER_OF_EXPLOIT_TRIALS_RL = 500\n",
    "BETA_EXPLOIT_RL = 0.05\n",
    "\n",
    "#RL Set Up\n",
    "GAMMA = 0.95\n",
    "BETA_RL = 0.05\n",
    "\n",
    "#BEACS Set Up\n",
    "DO_GA = True\n",
    "ENABLE_PEP = True\n",
    "LENGTH_OF_BEHAVIORAL_SEQUENCES = 1\n",
    "BETA_ALP = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment - Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "maze = gym.make(MAZE)\n",
    "# Set up probability to do a random action\n",
    "maze.env.set_prob_slippery(SLIPPERY_PROB)\n",
    "# Set up random attribute length\n",
    "maze.env.set_random_attribute_length(RANDOM_ATTRIBUTE_LENGTH)\n",
    "# Reset it, by putting an agent into random position\n",
    "maze.reset()\n",
    "# Render the state in ASCII\n",
    "maze.render('aliasing_human')\n",
    "# Get environmental state transitions\n",
    "#maze.env.get_theoritical_probabilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of BEACS - Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cfg_explore = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=METRICS_TRIAL_FREQUENCY_EXPLORE,\n",
    "    do_pep=ENABLE_PEP,\n",
    "    do_ga=DO_GA,\n",
    "    beta_alp=BETA_ALP,\n",
    "    beta_rl=BETA_RL,\n",
    "    gamma=GAMMA,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=EPSILON,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_bseq=1000,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8,\n",
    "    bs_max=LENGTH_OF_BEHAVIORAL_SEQUENCES\n",
    ")\n",
    "\n",
    "agent_explore = BEACS(cfg_explore)\n",
    "population_explore, metrics_explore = agent_explore.explore(maze, NUMBER_OF_EXPLORE_TRIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_trial_frequency_explore = cfg_explore.metrics_trial_frequency\n",
    "\n",
    "metrics_df = parse_metrics_to_df(metrics_explore, metrics_trial_frequency_explore, None, None)\n",
    "plot_performance(agent_explore, maze, metrics_df, cfg_explore, MAZE, metrics_trial_frequency_explore, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "first_trial, stable_trial, last_trial = _when_full_knowledge_is_achieved(metrics_explore)\n",
    "print(\"Full knowledge was achieved at trials \", first_trial, \", was stable at \", stable_trial, \n",
    "        \" and the last time it was achieved at \", last_trial)\n",
    "\n",
    "print(\"There are \", _how_many_peps_match_non_aliased_states(population_explore, maze),\n",
    "      \" enhanced classifer(s) that match a non-aliased states.\\n\")\n",
    "\n",
    "print(_maze_metrics(population_explore, maze))\n",
    "print(\"Mean reliable population specifity is \",\n",
    "      _mean_reliable_classifier_specificity(population_explore, maze))\n",
    "pep_error = _enhanced_effect_error(population_explore, maze, CLASSIFIER_LENGTH, RANDOM_ATTRIBUTE_LENGTH)\n",
    "print(\"Accumulated Error on PEP Probabilities :\", pep_error, \"%\\n\")\n",
    "\n",
    "agent_explore.zip_population()\n",
    "population_explore = agent_explore.get_population()\n",
    "\n",
    "print(_maze_metrics(population_explore, maze))\n",
    "print(\"Mean reliable population specifity is \",\n",
    "      _mean_reliable_classifier_specificity(population_explore, maze))\n",
    "pep_error = _enhanced_effect_error(population_explore, maze, CLASSIFIER_LENGTH, RANDOM_ATTRIBUTE_LENGTH)\n",
    "print(\"Accumulated Error on PEP Probabilities :\", pep_error, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population_explore.sort(key=lambda cl: -cl.fitness)\n",
    "population_explore_to_display = [cl for cl in population_explore]\n",
    "for cl in population_explore_to_display:\n",
    "    print(cl)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "agent_explore.get_pai_states_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of BEACS - Exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cfg_exploit_no_rl = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_pep=ENABLE_PEP,\n",
    "    do_ga=False,\n",
    "    beta_alp=BETA_ALP,\n",
    "    beta_rl=BETA_EXPLOIT_NO_RL,\n",
    "    gamma=GAMMA,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.0,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_bseq=1000,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8,\n",
    "    bs_max=LENGTH_OF_BEHAVIORAL_SEQUENCES\n",
    ")\n",
    "\n",
    "agent_exploit_no_rl = BEACS(cfg_exploit_no_rl, population_explore)\n",
    "population_exploit_no_rl, metrics_exploit_no_rl = agent_exploit_no_rl.exploit(maze, NUMBER_OF_EXPLOIT_TRIALS_NO_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cfg_exploit_rl_start = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_pep=ENABLE_PEP,\n",
    "    do_ga=False,\n",
    "    beta_alp=BETA_ALP,\n",
    "    beta_rl=BETA_EXPLOIT_RL_START,\n",
    "    gamma=GAMMA,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.0,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_bseq=1000,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8,\n",
    "    bs_max=LENGTH_OF_BEHAVIORAL_SEQUENCES\n",
    ")\n",
    "\n",
    "agent_exploit_rl_start = BEACS(cfg_exploit_rl_start, population_exploit_no_rl)\n",
    "population_exploit_rl_start, metrics_exploit_rl_start = agent_exploit_rl_start.exploit(maze, NUMBER_OF_EXPLOIT_TRIALS_RL_START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cfg_exploit_rl = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_pep=ENABLE_PEP,\n",
    "    do_ga=False,\n",
    "    beta_alp=BETA_ALP,\n",
    "    beta_rl=BETA_EXPLOIT_RL,\n",
    "    gamma=GAMMA,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.0,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_bseq=1000,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8,\n",
    "    bs_max=LENGTH_OF_BEHAVIORAL_SEQUENCES\n",
    ")\n",
    "\n",
    "agent_exploit_rl = BEACS(cfg_exploit_rl, population_exploit_rl_start)\n",
    "population_exploit_rl, metrics_exploit_rl = agent_exploit_rl.exploit(maze, NUMBER_OF_EXPLOIT_TRIALS_RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_trial_frequency_explore = cfg_explore.metrics_trial_frequency\n",
    "metrics_trial_frequency_exploit = 1\n",
    "\n",
    "metrics_exploit = metrics_exploit_no_rl.copy()\n",
    "for idx, item in enumerate(metrics_exploit_rl_start):\n",
    "    tmp = item.copy()\n",
    "    tmp['trial'] += NUMBER_OF_EXPLOIT_TRIALS_NO_RL\n",
    "    metrics_exploit.append(tmp)\n",
    "for idx, item in enumerate(metrics_exploit_rl):\n",
    "    tmp = item.copy()\n",
    "    tmp['trial'] += NUMBER_OF_EXPLOIT_TRIALS_NO_RL + NUMBER_OF_EXPLOIT_TRIALS_RL_START\n",
    "    metrics_exploit.append(tmp)\n",
    "\n",
    "metrics_df = parse_metrics_to_df(metrics_explore, metrics_trial_frequency_explore, metrics_exploit, metrics_trial_frequency_exploit)\n",
    "plot_performance(agent_exploit_rl, maze, metrics_df, cfg_exploit_rl, MAZE, metrics_trial_frequency_explore, [NUMBER_OF_EXPLOIT_TRIALS_NO_RL,NUMBER_OF_EXPLOIT_TRIALS_RL_START,NUMBER_OF_EXPLOIT_TRIALS_RL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avg_step_explore = 0\n",
    "for trial in metrics_explore:\n",
    "    avg_step_explore += trial['steps_in_trial']\n",
    "avg_step_explore /= NUMBER_OF_EXPLORE_TRIALS / metrics_trial_frequency_explore\n",
    "print(\"Average number of steps to solve the maze is \",avg_step_explore,\n",
    "      \" for a total of \", NUMBER_OF_EXPLORE_TRIALS, \" trials in EXPLORATION\")\n",
    "\n",
    "avg_step_exploit_no_rl = 0\n",
    "for trial in metrics_exploit_no_rl:\n",
    "    avg_step_exploit_no_rl += trial['steps_in_trial']\n",
    "avg_step_exploit_no_rl /= NUMBER_OF_EXPLOIT_TRIALS_NO_RL\n",
    "print(\"Average number of steps to solve the maze is \",avg_step_exploit_no_rl,\n",
    "      \" for a total of \", NUMBER_OF_EXPLOIT_TRIALS_NO_RL, \" trials in EXPLOITATION without Reinforcement Module\")\n",
    "\n",
    "avg_step_exploit_rl_start = 0\n",
    "for trial in metrics_exploit_rl_start:\n",
    "    avg_step_exploit_rl_start += trial['steps_in_trial']\n",
    "avg_step_exploit_rl_start /= NUMBER_OF_EXPLOIT_TRIALS_RL_START\n",
    "print(\"Average number of steps to solve the maze is \",avg_step_exploit_rl_start,\n",
    "      \" for a total of \", NUMBER_OF_EXPLOIT_TRIALS_RL_START, \" trials in EXPLOITATION starting Reinforcement Module\")\n",
    "\n",
    "avg_step_exploit_rl = 0\n",
    "for trial in metrics_exploit_rl:\n",
    "    avg_step_exploit_rl += trial['steps_in_trial']\n",
    "avg_step_exploit_rl /= NUMBER_OF_EXPLOIT_TRIALS_RL\n",
    "print(\"Average number of steps to solve the maze is \",avg_step_exploit_rl,\n",
    "      \" for a total of \", NUMBER_OF_EXPLOIT_TRIALS_RL, \" trials in EXPLOITATION with Reinforcement Module\")\n",
    "\n",
    "print(_maze_metrics(population_explore, maze))\n",
    "print(_maze_metrics(population_exploit_no_rl, maze))\n",
    "print(_maze_metrics(population_exploit_rl_start, maze))\n",
    "print(_maze_metrics(population_exploit_rl, maze))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population_exploit_rl.sort(key=lambda cl: -cl.fitness)\n",
    "population_exploit_rl_to_display = [cl for cl in population_exploit_rl ]\n",
    "#    if (not cl.behavioral_sequence)]\n",
    "print(len(population_exploit_rl_to_display))\n",
    "print(\"\\n\")\n",
    "for cl in population_exploit_rl_to_display:\n",
    "    print(cl)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
