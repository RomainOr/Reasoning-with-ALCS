{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    file, You can obtain one at http://mozilla.org/MPL/2.0/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be sure that all modules listed below are installed on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, operator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statsmodels.stats import weightstats as stests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameter to build seaborn boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, update the path where all data are located.\n",
    "# All computed p-values are gathered in a CSV file saved in the folder 'path'\n",
    "# whose file name depends on the experiment results you want to see\n",
    "path = './'\n",
    "offset_path = len(path)\n",
    "\n",
    "#beacs_no_bias = 'Debiased Beacs without CRACS without RA.json'\n",
    "#beacs = 'Beacs without CRACS without RA.json'\n",
    "\n",
    "beacs_no_bias = 'Debiased Beacs without CRACS with RA.json'\n",
    "beacs = 'Beacs without CRACS with RA.json'\n",
    "\n",
    "exp_list = [\n",
    "    beacs_no_bias,\n",
    "    beacs\n",
    "]\n",
    "\n",
    "exp_list_names = [\n",
    "    'BEACS-debiased',\n",
    "    'BEACS'\n",
    "]\n",
    "\n",
    "# Font size et figuresize parameters for plotting\n",
    "figure_size = (20, 10)\n",
    "axe_label_fontsize = '28'\n",
    "tick_label_fontsize = '24'\n",
    "legend_fontsize = '24'\n",
    "\n",
    "# Significance level for p-values\n",
    "alpha = 0.05\n",
    "stat_file_name = 'stats'\n",
    "\n",
    "# What to do ...\n",
    "produce_graph = True\n",
    "produce_stat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_latex_line():\n",
    "    with open(path + beacs_no_bias) as beacs_no_bias_json_file:\n",
    "        with open(path + beacs) as beacs_json_file:\n",
    "            beacs_no_bias_json = json.load(beacs_no_bias_json_file)\n",
    "            beacs_no_bias_json.sort(key=operator.itemgetter('maze'))\n",
    "            beacs_json = json.load(beacs_json_file)\n",
    "            beacs_json.sort(key=operator.itemgetter('maze'))\n",
    "            for beacs_no_bias_item, beacs_item in zip(beacs_no_bias_json, beacs_json):\n",
    "                string_to_print = \"\"\n",
    "                if beacs_no_bias_item['maze'][:-3] == \"Woods101demi\":\n",
    "                    string_to_print += \"Woods101.5\"\n",
    "                else:\n",
    "                    string_to_print += beacs_no_bias_item['maze'][:-3]\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_item['avg_population'], 0))+\"(\"+str(round(beacs_item['std_population'], 0))+\")\"\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_no_bias_item['avg_population'], 0))+\"(\"+str(round(beacs_no_bias_item['std_population'], 0))+\")\"\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_item['avg_knowledge'], 2))+\"(\"+str(round(beacs_item['std_knowledge'], 2))+\")\"\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_no_bias_item['avg_knowledge'], 2))+\"(\"+str(round(beacs_no_bias_item['std_knowledge'], 2))+\")\"\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_item['avg_ep_error_list'], 2))+\"(\"+str(round(beacs_item['std_ep_error_list'], 2))+\")\"\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_no_bias_item['avg_ep_error_list'], 2))+\"(\"+str(round(beacs_no_bias_item['std_ep_error_list'], 2))+\")\"\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_item['avg_exploit_rl'], 2))+\"(\"+str(round(beacs_item['std_exploit_rl'], 2))+\")\"\n",
    "                string_to_print += \" & \"\n",
    "                string_to_print += str(round(beacs_no_bias_item['avg_exploit_rl'], 2))+\"(\"+str(round(beacs_no_bias_item['std_exploit_rl'], 2))+\") \\\\\\\\\"\n",
    "                print(string_to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please, do not modify any lines of code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path, exp_list):\n",
    "    raw_data = []\n",
    "    for name in exp_list:\n",
    "        json_data_from_lcs = path + name\n",
    "        with open(json_data_from_lcs) as json_file:\n",
    "            raw_data_from_lcs = json.load(json_file)\n",
    "            raw_data.append(raw_data_from_lcs)\n",
    "    return raw_data\n",
    "\n",
    "# Call function to prepare plotting data\n",
    "raw_data = read_json(path, exp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing pandas plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pandas_plotting_data(raw_data, exp_list, exp_list_names):\n",
    "    cleaned_data = {\n",
    "        'LCS':[],\n",
    "        'Maze':[],\n",
    "        'Knowledge (%)':[],\n",
    "        'Population of classifiers':[],\n",
    "        'Reliable classifiers ratio':[],\n",
    "        'Mean realiable classifier specificity':[],\n",
    "        'Average EP Accumulated Error (%)':[],\n",
    "        'Average steps to exit':[]\n",
    "    }\n",
    "    nb_of_environments = 0\n",
    "    for i in range(len(exp_list_names)):\n",
    "        for item in raw_data[i]:\n",
    "            if 'time' not in item.keys():\n",
    "                nb_of_environments += 1\n",
    "                for idx in range(30):\n",
    "                    cleaned_data['LCS'].append(exp_list_names[i])\n",
    "                    if item['maze'][:-3] == \"Woods101demi\":\n",
    "                        cleaned_data['Maze'].append(\"Woods101.5\")\n",
    "                    else:\n",
    "                        cleaned_data['Maze'].append(item['maze'][:-3])\n",
    "                    cleaned_data['Knowledge (%)'].append(\n",
    "                        item['knowledge_list'][idx]\n",
    "                    )\n",
    "                    cleaned_data['Population of classifiers'].append(\n",
    "                        item['population_list'][idx]\n",
    "                    )\n",
    "                    cleaned_data['Reliable classifiers ratio'].append(\n",
    "                        float(item['reliable_list'][idx]) / item['population_list'][idx]\n",
    "                    )\n",
    "                    cleaned_data['Mean realiable classifier specificity'].append(\n",
    "                        item['mean_reliable_classifier_specificity_list'][idx]\n",
    "                    )\n",
    "                    cleaned_data['Average EP Accumulated Error (%)'].append(\n",
    "                        item['ep_error_list'][idx]\n",
    "                    )\n",
    "                    cleaned_data['Average steps to exit'].append(\n",
    "                        item['avg_exploit_rl_list'][idx]\n",
    "                    )\n",
    "\n",
    "    nb_of_environments /= len(exp_list)\n",
    "    pandas_data = pd.DataFrame(cleaned_data)\n",
    "    sorted_pandas_data = pandas_data.sort_values(\"Maze\")\n",
    "    return nb_of_environments, sorted_pandas_data\n",
    "\n",
    "nb_of_environments, pandas_data = prepare_pandas_plotting_data(raw_data, exp_list, exp_list_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting boxplots with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc={\n",
    "    'axes.labelsize':axe_label_fontsize,\n",
    "    'xtick.labelsize':tick_label_fontsize,\n",
    "    'ytick.labelsize':tick_label_fontsize\n",
    "}\n",
    "sns.set(context='notebook', style='ticks', rc=rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(pandas_data, Y, lcs_name):\n",
    "    \n",
    "    #palette = sns.color_palette('pastel')\n",
    "    #color1=palette[0]\n",
    "    #color2=palette[2]\n",
    "    #pal = [color1, color2]\n",
    "    \n",
    "    # Build the main figure\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    sns.stripplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        edgecolor='gray',\n",
    "        jitter=True,\n",
    "        linewidth = 1,\n",
    "        dodge=True,\n",
    "        #palette=pal,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        fliersize=0,\n",
    "        #palette=pal,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )\n",
    "\n",
    "    # Set up x tick labels and x label correctly\n",
    "    xlocs, xlabels = plt.xticks() \n",
    "    plt.xticks(np.arange(nb_of_environments)+0.5, xlabels, rotation = 45, horizontalalignment = 'right')\n",
    "    plt.xlabel('')\n",
    "\n",
    "    # Hide the horizontal gridlines\n",
    "    ax.yaxis.grid(False)\n",
    "\n",
    "    # Show the vertical gridlines\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    # Set up minor ticks and align label of major ticks on minor ticks\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(0.5))\n",
    "    dx = (((figure_size[0] * 100 / 4.))/nb_of_environments - 10)/72.; dy = 0/72. # Width in inches converted into pixels depending on default DPI\n",
    "    offset = matplotlib.transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "    for label in ax.xaxis.get_majorticklabels():\n",
    "        label.set_transform(label.get_transform() - offset)\n",
    "\n",
    "    # Set up legend\n",
    "    handles, _ = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[0:len(lcs_name)], lcs_name[0:len(lcs_name)], frameon=False, fontsize=legend_fontsize, bbox_to_anchor=(0.5, 1.05), borderaxespad=0., loc='center', ncol=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_whole_population_and_reliable_ratio(pandas_data, lcs_name):\n",
    "    # Build the main figure\n",
    "    fig, ax = plt.subplots(1, 2, figsize=figure_size)\n",
    "    \n",
    "    sns.stripplot(\n",
    "        x = 'Maze',\n",
    "        y = 'Population of classifiers',\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        edgecolor='gray',\n",
    "        jitter=True,\n",
    "        linewidth = 1,\n",
    "        dodge=True,\n",
    "        #palette=pal,\n",
    "        palette='pastel',\n",
    "        ax = ax[0]\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        x = 'Maze',\n",
    "        y = 'Population of classifiers',\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        fliersize=0,\n",
    "        #palette=pal,\n",
    "        palette='pastel',\n",
    "        ax = ax[0]\n",
    "    )\n",
    "    \n",
    "    handles, labels = ax[0].get_legend_handles_labels()\n",
    "    fig.legend(handles[0:len(lcs_name)], lcs_name[0:len(lcs_name)], frameon=False, fontsize=legend_fontsize, borderaxespad=1., loc='upper center', ncol=3)\n",
    "    \n",
    "    # Get first subplot correctly\n",
    "    plt.sca(ax[0])\n",
    "    \n",
    "    # Set up x tick labels and x label correctly\n",
    "    xlocs, xlabels = plt.xticks() \n",
    "    plt.xticks(np.arange(nb_of_environments)+0.5, xlabels, rotation = 45, horizontalalignment = 'right', fontsize=16)\n",
    "    plt.xlabel('')\n",
    "\n",
    "    # Hide the horizontal gridlines\n",
    "    ax[0].yaxis.grid(False)\n",
    "\n",
    "    # Show the vertical gridlines\n",
    "    ax[0].xaxis.grid(True)\n",
    "\n",
    "    # Set up minor ticks and align label of major ticks on minor ticks\n",
    "    ax[0].xaxis.set_minor_locator(plt.MultipleLocator(0.5))\n",
    "    #dx = (((figure_size[0] * 100 / 4.))/nb_of_environments - 10)/72.; dy = 0/72. # Width in inches converted into pixels depending on default DPI\n",
    "    #offset = matplotlib.transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "    #for label in ax[0].xaxis.get_majorticklabels():\n",
    "    #    label.set_transform(label.get_transform() - offset)\n",
    "        \n",
    "    # Set up legend\n",
    "    ax[0].get_legend().remove()\n",
    "\n",
    "    sns.stripplot(\n",
    "        x = 'Maze',\n",
    "        y = 'Reliable classifiers ratio',\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        edgecolor='gray',\n",
    "        jitter=True,\n",
    "        linewidth = 1,\n",
    "        dodge=True,\n",
    "        palette='pastel',\n",
    "        ax = ax[1]\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        x = 'Maze',\n",
    "        y = 'Reliable classifiers ratio',\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        fliersize=0,\n",
    "        palette='pastel',\n",
    "        ax = ax[1]\n",
    "    )\n",
    "    \n",
    "    # Get second subplot correctly\n",
    "    plt.sca(ax[1])\n",
    "    \n",
    "    # Set up x tick labels and x label correctly\n",
    "    xlocs, xlabels = plt.xticks() \n",
    "    plt.xticks(np.arange(nb_of_environments)+0.5, xlabels, rotation = 45, horizontalalignment = 'right', fontsize=16)\n",
    "    plt.xlabel('')\n",
    "\n",
    "    # Hide the horizontal gridlines\n",
    "    ax[1].yaxis.grid(False)\n",
    "\n",
    "    # Show the vertical gridlines\n",
    "    ax[1].xaxis.grid(True)\n",
    "\n",
    "    # Set up minor ticks and align label of major ticks on minor ticks\n",
    "    ax[1].xaxis.set_minor_locator(plt.MultipleLocator(0.5))\n",
    "    #dx = (((figure_size[0] * 100 / 4.))/nb_of_environments - 10)/72.; dy = 0/72. # Width in inches converted into pixels depending on default DPI\n",
    "    #offset = matplotlib.transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "    #for label in ax[1].xaxis.get_majorticklabels():\n",
    "    #    label.set_transform(label.get_transform() - offset )\n",
    "\n",
    "    # Set up legend\n",
    "    ax[1].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knowledge(pandas_data, zipped:bool=True):\n",
    "    plot_figure(pandas_data, Y='Knowledge (%)', lcs_name=exp_list_names)\n",
    "\n",
    "def plot_mean_classifier_specificity(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Mean realiable classifier specificity', lcs_name=exp_list_names)\n",
    "\n",
    "def plot_ep_accumulated_error(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Average EP Accumulated Error (%)', lcs_name=exp_list_names)\n",
    "\n",
    "def plot_avg_steps_to_exit(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Average steps to exit', lcs_name=exp_list_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_graph:\n",
    "    plot_knowledge(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_graph:\n",
    "    plot_whole_population_and_reliable_ratio(pandas_data, exp_list_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_graph:\n",
    "    plot_mean_classifier_specificity(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_graph:\n",
    "    plot_ep_accumulated_error(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_graph:\n",
    "    plot_avg_steps_to_exit(pandas_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing statistical data from raw read json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_stat:\n",
    "    raw_list_by_env_name = {}\n",
    "    for i in range(len(exp_list_names)):\n",
    "        for item in raw_data[i]:\n",
    "            if 'time' not in item.keys():\n",
    "                if item['maze'] not in raw_list_by_env_name.keys():\n",
    "                    raw_list_by_env_name[item['maze']] = {\n",
    "                        'knowledge_list' : [],\n",
    "                        'population_list' : [],\n",
    "                        #'reliable_ratio_list' : [],\n",
    "                        #'mean_reliable_classifier_specificity_list' : [],\n",
    "                        'EP_Accumulated_Error' : [],\n",
    "                        'Average_steps_to_exit' : []\n",
    "                    }\n",
    "                raw_list_by_env_name[item['maze']]['knowledge_list'].append(\n",
    "                    np.array(item['knowledge_list']))\n",
    "                raw_list_by_env_name[item['maze']]['population_list'].append(\n",
    "                    np.array(item['population_list']))\n",
    "                #raw_list_by_env_name[item['maze']]['reliable_ratio_list'].append(\n",
    "                #    np.array( \n",
    "                #        [float(b) / m for b,m in zip(item['reliable_list'], item['population_list'])]\n",
    "                #    ))\n",
    "                #raw_list_by_env_name[item['maze']]['mean_reliable_classifier_specificity_list'].append(\n",
    "                #    np.array(item['mean_reliable_classifier_specificity_list']))\n",
    "                raw_list_by_env_name[item['maze']]['EP_Accumulated_Error'].append(\n",
    "                    np.array(item['ep_error_list']))\n",
    "                raw_list_by_env_name[item['maze']]['Average_steps_to_exit'].append(\n",
    "                    np.array(item['avg_exploit_rl_list']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_stat:\n",
    "    alcs = \"\"+exp_list_names[0]+\"-\"+exp_list_names[1]+\"\"\n",
    "    raw_statistical_data = {\n",
    "        'Maze':[],\n",
    "        'Metric':[],\n",
    "        'ALCS':[],\n",
    "        'Alternative':[],\n",
    "        'Degrees of freedom':[],\n",
    "        'P Value':[],\n",
    "        'Null Hypothesis':[]\n",
    "    }\n",
    "    for env_name in raw_list_by_env_name.keys():\n",
    "        for metric in raw_list_by_env_name[env_name].keys():\n",
    "            for i in range(1):\n",
    "                raw_statistical_data['Maze'].append(env_name)\n",
    "                raw_statistical_data['Metric'].append(metric)\n",
    "                raw_statistical_data['ALCS'].append(alcs)\n",
    "                x1 = np.array(raw_list_by_env_name[env_name][metric][0])\n",
    "                x2 = np.array(raw_list_by_env_name[env_name][metric][1])\n",
    "                if i == 0:\n",
    "                    alt = 'two-sided'\n",
    "                elif i == 1:\n",
    "                    alt = 'larger'\n",
    "                else:\n",
    "                    alt = 'smaller'\n",
    "                raw_statistical_data['Alternative'].append(alt)\n",
    "                tstats, pvalue, dof = stests.ttest_ind(x1, x2, alternative=alt, usevar='unequal', value=0)\n",
    "                raw_statistical_data['Degrees of freedom'].append(dof)\n",
    "                raw_statistical_data['P Value'].append(pvalue)\n",
    "                if pvalue<alpha:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Reject')\n",
    "                else:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Accept')\n",
    "    statistical_pandas = pd.DataFrame(raw_statistical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_stat:\n",
    "    statistical_pandas.to_csv(path + stat_file_name + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
