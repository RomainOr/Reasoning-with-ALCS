{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    file, You can obtain one at http://mozilla.org/MPL/2.0/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Enable automatic module reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# To ease the loading of modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load environments\n",
    "import gymnasium as gym\n",
    "import gymnasium_mazes\n",
    "\n",
    "# Allow to parallelize all benchmarks to do\n",
    "import ray\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent - BEACS - BENCHMARKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environmental Set Up\n",
    "CLASSIFIER_LENGTH = 8\n",
    "NUMBER_OF_POSSIBLE_ACTIONS = 8\n",
    "SLIPPERY_PROB = 0.25\n",
    "\n",
    "#Exploration Set Up\n",
    "NUMBER_OF_EXPLORE_TRIALS = 5000\n",
    "METRICS_TRIAL_FREQUENCY_EXPLORE = 100\n",
    "EPSILON = 0.8\n",
    "BETA_ALP = 0.05\n",
    "\n",
    "#Exploitation Set Up\n",
    "NUMBER_OF_EXPLOIT_TRIALS_NO_RL = 500\n",
    "BETA_EXPLOIT_NO_RL = 0.05\n",
    "NUMBER_OF_EXPLOIT_TRIALS_RL_START = 500\n",
    "BETA_EXPLOIT_RL_START = 0.05\n",
    "NUMBER_OF_EXPLOIT_TRIALS_RL = 500\n",
    "BETA_EXPLOIT_RL = 0.05\n",
    "\n",
    "#RL Set Up\n",
    "GAMMA = 0.95\n",
    "BETA_RL = 0.05\n",
    "\n",
    "#GA Set Up\n",
    "CROSSOVER = 0.8\n",
    "MUTATION = 0.3\n",
    "\n",
    "#BEACS Set Up\n",
    "ENABLE_EP = True\n",
    "LENGTH_OF_BEHAVIORAL_SEQUENCES = 2\n",
    "\n",
    "#Parallelization and Iterations for Stats\n",
    "NUMBER_OF_ITERATIONS_TO_BENCH = 2\n",
    "\n",
    "JSON_RESULTS_FILENAME = \"test.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching Ray for Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Local Mode\n",
    "runtime_env= {\"working_dir\": \"..\"}\n",
    "ray.init(ignore_reinit_error=True, runtime_env=runtime_env)\n",
    "# Remote Mode\n",
    "#runtime_env= {\"working_dir\": \".\"}\n",
    "#ray.init(address='auto', _redis_password='5241590000000000', runtime_env=runtime_env)\n",
    "#time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking - Maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom functions for getting available environments in Gym depending on the type of mazes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_envs_typeIII = lambda env: \"Maze10-\" in env or \"MazeE1\" in env \\\n",
    "    or \"MazeE2\" in env or \"Woods10\" in env\n",
    "\n",
    "filter_envs_typeII = lambda env: \"MazeF4\" in env or \"Maze7\" in env \\\n",
    "    or \"MiyazakiB\" in env\n",
    "\n",
    "filter_envs_typeI = lambda env: \"MazeB\" in env or \"MazeD\" in env \\\n",
    "    or \"Littman\" in env or \"MiyazakiA\" in env \\\n",
    "    or \"Cassandra\" in env\n",
    "\n",
    "filter_envs_na = lambda env: \"MazeF1\" in env or \"MazeF2\" in env \\\n",
    "    or \"MazeF3\" in env or \"Woods14\" in env \\\n",
    "    or \"Maze4\" in env or \"Maze5\" in env \\\n",
    "    or \"MazeA\" in env\n",
    "\n",
    "all_envs = [env for env in gym.envs.registry]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get benchmark value on one gym environment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def bench_on_maze(env):\n",
    "    # To ease the loading of modules\n",
    "    import os\n",
    "    import sys\n",
    "    import time\n",
    "    \n",
    "    # Load BEACS module\n",
    "    from agents.beacs import BEACS, BEACSConfiguration\n",
    "\n",
    "    # Load Metrics\n",
    "    from my_examples.metrics.MazeMetrics import \\\n",
    "        _maze_metrics, \\\n",
    "        _how_many_eps_match_non_aliased_states, \\\n",
    "        _mean_reliable_classifier_specificity, \\\n",
    "        _when_full_knowledge_is_achieved, \\\n",
    "        _enhanced_effect_error\n",
    "\n",
    "    # Load environments\n",
    "    import gymnasium as gym\n",
    "    import gymnasium_mazes\n",
    "    \n",
    "    cfg_explore = BEACSConfiguration(\n",
    "        classifier_length=CLASSIFIER_LENGTH,\n",
    "        number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "        user_metrics_collector_fcn=_maze_metrics,\n",
    "        metrics_trial_frequency=METRICS_TRIAL_FREQUENCY_EXPLORE,\n",
    "        do_ep=ENABLE_EP,\n",
    "        beta_alp=BETA_ALP,\n",
    "        beta_rl=BETA_RL,\n",
    "        gamma=GAMMA,\n",
    "        epsilon=EPSILON,\n",
    "        u_max=CLASSIFIER_LENGTH,\n",
    "        mu=MUTATION,\n",
    "        chi=CROSSOVER,\n",
    "        bs_max=LENGTH_OF_BEHAVIORAL_SEQUENCES\n",
    "    )\n",
    "\n",
    "    cfg_exploit_no_rl = BEACSConfiguration(\n",
    "        classifier_length=CLASSIFIER_LENGTH,\n",
    "        number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "        user_metrics_collector_fcn=_maze_metrics,\n",
    "        metrics_trial_frequency=1,\n",
    "        beta_rl=BETA_EXPLOIT_NO_RL,\n",
    "        gamma=GAMMA,\n",
    "        epsilon=0.2\n",
    "    )\n",
    "\n",
    "    cfg_exploit_rl_start = BEACSConfiguration(\n",
    "        classifier_length=CLASSIFIER_LENGTH,\n",
    "        number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "        user_metrics_collector_fcn=_maze_metrics,\n",
    "        metrics_trial_frequency=1,\n",
    "        beta_rl=BETA_EXPLOIT_RL_START,\n",
    "        gamma=GAMMA,\n",
    "        epsilon=0.0\n",
    "    )\n",
    "\n",
    "    cfg_exploit_rl = BEACSConfiguration(\n",
    "        classifier_length=CLASSIFIER_LENGTH,\n",
    "        number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "        user_metrics_collector_fcn=_maze_metrics,\n",
    "        metrics_trial_frequency=1,\n",
    "        beta_rl=BETA_EXPLOIT_RL,\n",
    "        gamma=GAMMA,\n",
    "        epsilon=0.0,\n",
    "    )\n",
    "        \n",
    "    # Initialize environment\n",
    "    maze = gym.make(env, slippery_prob=SLIPPERY_PROB)\n",
    "\n",
    "    # Reset it, by putting an agent into random position\n",
    "    maze.reset()\n",
    "\n",
    "    # Training of BEACS - Exploration\n",
    "    explore_start_time = time.process_time()\n",
    "    agent_explore = BEACS(cfg_explore)\n",
    "    population_explore, metrics_explore = agent_explore.explore(maze, NUMBER_OF_EXPLORE_TRIALS)\n",
    "    explore_end_time = time.process_time()\n",
    "    \n",
    "    # Applying CRACS\n",
    "    cracs_start_time = time.process_time()\n",
    "    agent_explore.apply_CRACS()\n",
    "    cracs_end_time = time.process_time()\n",
    "    population_explore = agent_explore.get_population()\n",
    "    \n",
    "    eps_match_non_aliased_states = _how_many_eps_match_non_aliased_states(population_explore, maze)\n",
    "    ep_error = _enhanced_effect_error(population_explore, maze, CLASSIFIER_LENGTH)\n",
    "    mean_reliable_classifier_specificity, mean_reliable_no_bs_classifier_specificity, mean_reliable_bs_classifier_specificity = _mean_reliable_classifier_specificity(population_explore, maze)\n",
    "    maze_metrics = _maze_metrics(population_explore, maze)\n",
    "    \n",
    "    first_trial, stable_trial, last_trial = _when_full_knowledge_is_achieved(metrics_explore)\n",
    "\n",
    "    \n",
    "    ### Using BEACS - Compressed population\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    \n",
    "    # Using BEACS - Exploitation - No RL module\n",
    "    agent_exploit_no_rl = BEACS(cfg_exploit_no_rl, population_explore)\n",
    "    population_exploit_no_rl, metrics_exploit_no_rl = agent_exploit_no_rl.exploit(maze, NUMBER_OF_EXPLOIT_TRIALS_NO_RL)\n",
    "\n",
    "    # Using BEACS - Exploitation - Starting using RL module\n",
    "    agent_exploit_rl_start = BEACS(cfg_exploit_rl_start, population_exploit_no_rl)\n",
    "    population_exploit_rl_start, metrics_exploit_rl_start = agent_exploit_rl_start.exploit(maze, NUMBER_OF_EXPLOIT_TRIALS_RL_START)\n",
    "\n",
    "    # Using BEACS - Exploitation - Using RL module\n",
    "    agent_exploit_rl = BEACS(cfg_exploit_rl, population_exploit_rl_start)\n",
    "    population_exploit_rl, metrics_exploit_rl = agent_exploit_rl.exploit(maze, NUMBER_OF_EXPLOIT_TRIALS_RL)\n",
    "\n",
    "    end_time = time.process_time()\n",
    "    \n",
    "    # Get average 'steps to exit' in all exploitation modes\n",
    "    avg_step_exploit_no_rl = 0\n",
    "    for trial in metrics_exploit_no_rl:\n",
    "        avg_step_exploit_no_rl += trial['steps_in_trial']\n",
    "    avg_step_exploit_no_rl /= NUMBER_OF_EXPLOIT_TRIALS_NO_RL\n",
    "    avg_step_exploit_rl_start = 0\n",
    "    for trial in metrics_exploit_rl_start:\n",
    "        avg_step_exploit_rl_start += trial['steps_in_trial']\n",
    "    avg_step_exploit_rl_start /= NUMBER_OF_EXPLOIT_TRIALS_RL_START\n",
    "    avg_step_exploit_rl = 0\n",
    "    for trial in metrics_exploit_rl:\n",
    "        avg_step_exploit_rl += trial['steps_in_trial']\n",
    "    avg_step_exploit_rl /= NUMBER_OF_EXPLOIT_TRIALS_RL\n",
    "    \n",
    "    result = {\n",
    "        'maze' : env,\n",
    "        \n",
    "        'knowledge' : maze_metrics['knowledge'],\n",
    "        'population' : maze_metrics['population'],\n",
    "        'numerosity' : maze_metrics['numerosity'],\n",
    "        'reliable' : maze_metrics['reliable'],\n",
    "        'mean_reliable_classifier_specificity' : mean_reliable_classifier_specificity,\n",
    "        'mean_reliable_bs_classifier_specificity' : mean_reliable_bs_classifier_specificity,\n",
    "        'mean_reliable_no_bs_classifier_specificity' : mean_reliable_no_bs_classifier_specificity,\n",
    "        'ep_error': ep_error,\n",
    "        'eps_match_non_aliased_states': eps_match_non_aliased_states,\n",
    "        \n",
    "        'full_knowledge_first_trial' : first_trial,\n",
    "        'full_knowledge_stable_trial' : stable_trial,\n",
    "        'full_knowledge_last_trial' : last_trial,\n",
    "        \n",
    "        'avg_exploit_no_rl' : avg_step_exploit_no_rl,\n",
    "        'avg_exploit_rl_start' : avg_step_exploit_rl_start,\n",
    "        'avg_exploit_rl' : avg_step_exploit_rl,\n",
    "        \n",
    "        'memory_of_pai_states' : agent_explore.get_pai_states_memory(), \n",
    "        \n",
    "        'explore_time' : explore_end_time - explore_start_time,\n",
    "        'cracs_time' : cracs_end_time - cracs_start_time,\n",
    "        'time' : (end_time - start_time)\n",
    "    }\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the list of environments to bench : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze_envs = []\n",
    "maze_envs_name = []\n",
    "for env in all_envs:\n",
    "    if filter_envs_typeIII(env) or filter_envs_typeII(env) or filter_envs_typeI(env) or filter_envs_na(env):\n",
    "        maze_envs_name.append(env)\n",
    "        for i in range(NUMBER_OF_ITERATIONS_TO_BENCH):\n",
    "            maze_envs.append(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from my_examples.metrics.MazeMetrics import compute_mean_and_stdev_for_one_env\n",
    "\n",
    "futures = [bench_on_maze.remote(env) for env in maze_envs]\n",
    "results = ray.get(futures)\n",
    "results = [compute_mean_and_stdev_for_one_env(env_name, results) for env_name in maze_envs_name]\n",
    "\n",
    "jsonString = json.dumps(results)\n",
    "jsonFile = open(JSON_RESULTS_FILENAME, \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
